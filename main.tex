\documentclass{article}
\title{kana: single-cell data analysis in the browser}
\usepackage{authblk}
\usepackage{hyperref}

\author[1]{Aaron Lun}
\affil[1]{Genentech, Inc. South San Francisco, CA}
\author[2]{Jayaram Kancherla}
\affil[2]{Genentech, Inc. South San Francisco, CA}

\begin{document}
\maketitle

\newcommand{\code}[1]{\texttt{#1}}

\section{Introduction}

We present \code{kana}, a web application for single-cell RNA-seq (scRNA-seq) data analysis inside the browser.
\code{kana} provides a streamlined one-click workflow for all steps in a typical scRNA-seq analysis \cite{amezquita2020orchestrating}, 
starting from quality control and finishing with marker detection.
Users can interactively explore the low-dimensional embeddings, clusterings and marker genes in an intuitive graphical interface that encourages iterative re-analysis.
Once finished, users can save their analysis and results for later examination or sharing with collaborators.

By taking advantage of new web technologies, \code{kana} can rapidly analyze genomics-scale datasets on the client's machine via any modern browser.
We do not require installation of any data analysis environments like R or Python, allowing \code{kana} to be used by audiences of varying computational skill.
We do not need a backend server to perform any of the calculations, simplifying deployment and reducing costs.
As the entire analysis is performed on the client machine, we avoid any data transfer and associated issues with ownership and privacy.

The \code{kana} application is available now at \url{https://www.jkanche.com/kana}.

\section{Application overview}

Given a scRNA-seq dataset, \code{kana} implements a routine analysis with the steps listed below.
We will not discuss the statistical and scientific rationale behind each step in much detail as this has been covered elsewhere \cite{oscabook} 

\begin{enumerate}
\item We import a gene-by-cell count matrix from the user's machine, typically in the form of Matrix Market files such as those produced by the Cellranger pipeline.
HDF5 files are also supported, either using the 10X HDF5 feature barcode matrix format or as H5AD files.
\item We compute common quality control (QC) metrics such as the total count, number of detected genes and proportion of mitochondrial counts.
Low-quality cells are then defined as those cells with outlier values for any of these metrics and are removed.
\item We perform scaling normalization based on the library size to remove cell-specific biases.
This is followed by a log-transformation to obtain log-normalized expression values.
\item We fit a trend to the per-gene variances with respect to the means, computed from the log-expression vaules.
We sort on the residuals to define a subset of highly variable genes (HVGs). 
\item We then perform principal components analysis (PCA) on the HVG subset of the log-expression.
This yields a few top PCs that capture the heterogeneity of the data in a compressed and denoised form.
\item We apply a variety of clustering techniques on the top PCs to generate discrete subpopulations.
Each cluster is characterized through differential expression analyses to detect its top markers.
\item We perform further dimensionality reduction on the top PCs to obtain two-dimensional embeddings for visualization. 
This includes the usual t-distributed stochastic neighbor embedding (t-SNE) and uniform manifold approximation and projection (UMAP).
\end{enumerate}

At each step, users can easily customize key parameters.
For example, we can adjust the thresholds used for the QC filters, the number of HVGs and top PCs, the granularity of the clustering, and more.
When parameters are modified for any step, all subsequent steps are automatically re-executed to propagate the change to downstream results.
Conversely, we do not rerun any steps upstream of the change to avoid unnecessary recomputation and reduce latency.

\section{Efficient compute with WebAssembly}

WebAssembly (Wasm) is an instruction format that provdes a web-executable compilation target for languages like C/C++, Go and Rust.
This allows us to turn the browser into a compute engine by integrating existing scientific libraries for bioinformatics data analysis (cite biowasm here).
To do so, we collected C++ implementations of the algorithms required for each analysis step:

\begin{itemize}
\item The \code{tatami} library \cite{tatami} provides an abstract interface to different matrix classes, focusing on row and column extraction.
While it supports the usual dense and sparse representations, its key feature is its support for delayed operations,
mimicking the \code{DelayedArray} package from Bioconductor \cite{delayedarray}.
This allows the creation of log-normalized matrices and HVG submatrices with no extra memory usage.
\item The \code{knncolle} library \cite{knncolle} wraps a number of nearest neighbor detection methods in a consistent interface.
This includes exact methods like vantage point tree search as well as approximate methods like Annoy \cite{annoy}.
It is equivalent to the \code{BiocNeighbors} package from Bioconductor \cite{biocneighbors}.
\item The \code{CppIrlba} library \cite{cppirlba} library contains a C++ port of the IRLBA algorithm \cite{baglama2005augmented} to efficiently obtain the top few PCs.
The code here was based on the C code in the \code{irlba} package \cite{irlba} with some refactoring to eliminate dependencies on R-specific libraries.
\item The \code{CppKmeans} library \cite{cppkmeans} contains C++ implementations of the Hartigan-Wong \cite{hartiganwong} and Lloyd algorithms \cite{lloyd} for k-means clustering.
In particular, the Hartigan-Wong implementation was translated from the Fortran code used by R's \code{kmeans} function.
\item The \code{CppWeightedLowess} library \cite{cppweightedlowess} contains a C++ implementation of the \code{weightedLowess} function in the \code{limma} package \cite{ritchie2015limma}.
This is based on the LOWESS implementation \cite{cleveland1979robust} from R's \code{lowess} function. 
\item The \code{qdtsne} library \cite{qdtsne} contains an implementation of the Barnes-Hut t-SNE algorithm \cite{maaten2014accelerating}.
This is mostly a refactored version of the code in the \code{Rtsne} package \cite{rtsne}.
Some additional optimizations have been applied to improve scalability.
\item The \code{umappp} library \cite{umappp} provides an implementation of the UMAP algorithm \cite{mcinnes2018umap}.
This is largely derived from code in the \code{uwot} package \cite{uwot}.
\item The \code{libscran} library implements high-level methods for scRNA-seq data analysis, ranging from quality control to clustering.
The code here originates from the \code{scran}, \code{scuttle} and \code{scater} packages \cite{lun2016step,lun2017scater} bundled together into a single C++ library for convenience. 
\end{itemize}

We compiled our C++ code to Wasm using the [Emscripten toolchain](https://emscripten.org/) to create Javascript-visible bindings.
This allows our Javascript code to easily call C++ functions and interact with instances of C++ classes via Wasm.

% NEED TO ADD TIMINGS.

\bibliography{ref.bib}
\bibliographystyle{plain}

\end{document}
