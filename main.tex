\documentclass{article}
\title{kana: single-cell data analysis in the browser}
\usepackage{authblk}
\usepackage{hyperref}
\usepackage{graphicx}

\author[1]{Aaron Lun}
\affil[1]{Genentech, Inc. South San Francisco, CA}
\author[1]{Jayaram Kancherla}

\begin{document}
\maketitle

\newcommand{\code}[1]{\texttt{#1}}

\section{Introduction}

We present \code{kana}, a web application for single-cell RNA-seq (scRNA-seq) data analysis inside the browser.
\code{kana} provides a streamlined one-click workflow for all steps in a typical scRNA-seq analysis \cite{amezquita2020orchestrating}, 
starting from quality control and finishing with marker detection.
Users can interactively explore the low-dimensional embeddings, clusterings and marker genes in an intuitive graphical interface that encourages iterative re-analysis.
Once finished, users can save their analysis and results for later examination or sharing with collaborators.

By taking advantage of new web technologies, \code{kana} can rapidly analyze genomics-scale datasets on the client's machine via any modern browser.
We do not require installation of any data analysis environments like R or Python, allowing \code{kana} to be used by audiences of varying computational skill.
We do not need a backend server to perform any of the calculations, simplifying deployment and reducing costs.
As the entire analysis is performed on the client machine, we avoid any data transfer and associated issues with ownership and privacy.

The \code{kana} application is available now at \url{https://www.jkanche.com/kana}.

\section{Application overview}

Given a scRNA-seq dataset, \code{kana} implements a routine analysis with the steps listed below.
We will not discuss the statistical and scientific rationale behind each step in much detail as this has been covered elsewhere \cite{oscabook} 

\begin{enumerate}
\item We import a gene-by-cell count matrix from the user's machine, typically in the form of Matrix Market files such as those produced by the Cellranger pipeline.
HDF5 files are also supported, either using the 10X HDF5 feature barcode matrix format or as H5AD files.
\item We compute common quality control (QC) metrics such as the total count, number of detected genes and proportion of mitochondrial counts.
Low-quality cells are then defined as those cells with outlier values for any of these metrics and are removed.
\item We perform scaling normalization based on the library size to remove cell-specific biases.
This is followed by a log-transformation to obtain log-normalized expression values.
\item We fit a trend to the per-gene variances with respect to the means, computed from the log-expression vaules.
We sort on the residuals to define a subset of highly variable genes (HVGs). 
\item We then perform principal components analysis (PCA) on the HVG subset of the log-expression.
This yields a few top PCs that capture the heterogeneity of the data in a compressed and denoised form.
\item We apply a variety of clustering techniques on the top PCs to generate discrete subpopulations.
Each cluster is characterized through differential expression analyses to detect its top markers.
\item We perform further dimensionality reduction on the top PCs to obtain two-dimensional embeddings for visualization. 
This includes the usual t-distributed stochastic neighbor embedding (t-SNE) and uniform manifold approximation and projection (UMAP).
\end{enumerate}

At each step, users can easily customize key parameters (Figure \ref{screenshot:analysis}).
For example, we can adjust the QC thresholds, the number of HVGs and top PCs, the granularity of the clustering, and more.
When parameters are modified for any step, all subsequent steps are automatically re-executed to propagate the change to downstream results.
Conversely, we do not rerun any steps upstream of the change to avoid unnecessary recomputation and reduce latency.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{screenshots/analysis.png}
\end{center}
\caption{Screenshot showing the analysis configuration panel in the \code{kana} application.
Clicking ``Analyze" will perform the entire analysis.}
\label{screenshot:analysis}
\end{figure}

Once each step of the analysis is complete, \code{kana} visualizes its results in a multi-panel layout (Figure \ref{screenshot:results}).
One panel contains a scatter plot for the low-dimensional embeddings, where each cell is a point that is colored by cluster identity or gene expression.
Another panel contains a table of marker statistics for a selected cluster, where potential marker genes are ranked and filtered according to the magnitude of upregulation over other clusters.
We also have a gallery to visualize miscellaneous details such as the distribution of QC metrics.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{screenshots/results.png}
\end{center}
\caption{Screenshot showing the multi-panel layout for results in the \code{kana} application.
The top-left panel is used for the low-dimensional embeddings,
the right panel contains the marker table for a selected cluster,
and the bottom-left panel contains a gallery of miscellaneous plots.}
\label{screenshot:results}
\end{figure}

Finally, users can export the analysis parameters and results for later inspection.
The exported analysis can be quickly reloaded in a new browser session, allowing users to view the results without repeating the computation.

\section{Client-side computation}

\subsection{Efficient compute with WebAssembly}

WebAssembly (Wasm) is an instruction format that provdes a web-executable compilation target for languages like C/C++, Go and Rust.
This allows us to turn the browser into a compute engine by integrating existing scientific libraries for bioinformatics data analysis (cite biowasm here).
To do so, we collected C++ implementations of the algorithms required for each analysis step:

\begin{itemize}
\item The \code{tatami} library \cite{tatami} provides an abstract interface to different matrix classes, based on the concepts in the \code{beachmat} package \cite{lun2018beachmat}. 
In addition to the usual dense and sparse representations, \code{tatami} also supports the delayed operations implemented in the \code{DelayedArray} package \cite{delayedarray}.
This allows the creation of log-normalized matrices and HVG submatrices with no extra memory usage.
\item The \code{knncolle} library \cite{knncolle} wraps a number of nearest neighbor detection methods in a consistent interface.
This includes exact methods like vantage point tree search as well as approximate methods like Annoy \cite{annoy}.
It is equivalent to the \code{BiocNeighbors} package from Bioconductor \cite{biocneighbors}.
\item The \code{CppIrlba} library \cite{cppirlba} library contains a C++ port of the IRLBA algorithm \cite{baglama2005augmented} to efficiently obtain the top few PCs.
The code here was based on the C code in the \code{irlba} package \cite{irlba} with some refactoring to eliminate dependencies on R-specific libraries.
\item The \code{CppKmeans} library \cite{cppkmeans} contains C++ implementations of the Hartigan-Wong \cite{hartiganwong} and Lloyd algorithms \cite{lloyd} for k-means clustering.
In particular, the Hartigan-Wong implementation was translated from the Fortran code used by R's \code{kmeans} function.
\item The \code{CppWeightedLowess} library \cite{cppweightedlowess} contains a C++ implementation of the \code{weightedLowess} function in the \code{limma} package \cite{ritchie2015limma}.
This is based on the LOWESS implementation \cite{cleveland1979robust} from R's \code{lowess} function. 
\item The \code{qdtsne} library \cite{qdtsne} contains an implementation of the Barnes-Hut t-SNE algorithm \cite{maaten2014accelerating}.
This is mostly a refactored version of the code in the \code{Rtsne} package \cite{rtsne}.
Some additional optimizations have been applied to improve scalability.
\item The \code{umappp} library \cite{umappp} provides an implementation of the UMAP algorithm \cite{mcinnes2018umap}.
This is largely derived from code in the \code{uwot} package \cite{uwot}.
\item The \code{libscran} library implements high-level methods for scRNA-seq data analysis, ranging from quality control to clustering.
The code here originates from the \code{scran}, \code{scuttle} and \code{scater} packages \cite{lun2016step,lun2017scater} bundled together into a single C++ library for convenience. 
\end{itemize}

We created the \code{scran.js} library (\url{https://github.com/jkanche/scran.js}) to implement Javascript-visible bindings to the C++ libraries.
We then compiled our C++ code to Wasm using the Emscripten toolchain, allowing \code{kana} to perform scRNA-seq-related calculations via standard calls to \code{scran.js} functions.
The same library can also be used in other web applications or outside the browser if an appropriate Wasm runtime is available.

% NEED TO ADD TIMINGS.

\subsection{Parallelization with Web Workers}

Web Workers are a simple mechanism for parallelization inside the browser.
They are primarily used for running background tasks in other threads so that the UI on the main thread can respond to user interaction.
In addition to this role, we use Web Workers for coarse-grained parallelization to speed up the scRNA-seq calculations.
Where possible, we parallelize within each step by using Emscripten to compile our C++ code with PThreads support.
This implements POSIX threads as Web Workers, allowing for transparent parallelization during calculation of QC metrics, nearest neighbor detection and marker scoring.
We also parallelize across steps by manually creating separate Web Workers for the execution of each step.
This is possible for the t-SNE, UMAP and clustering steps, which are independent of each other and can run concurrently.

A minor complication with PThreads is that we need to enable cross-origin isolation on the \code{kana} site.
Briefly, this is a security measure that prevents inappropriate data access from malicious scripts in the same browsing context.
Once cross-origin isolated, the site is permitted to use the \code{SharedArrayBuffer} for copy-free transfer of data between Web Workers.
To achieve this, we need to serve the \code{kana} assets with the appropriate cross-origin headers - specifically, the embedder and opener policies.
However, this may not always be possible, e.g., when hosting on institutional sites or public sites such as GitHub Pages.
Instead, we use a service worker to cache and re-serve \code{kana} with the correct headers,
ensuring that it can be easily deployed in a range of hosting environments.

\subsection{Creating layered sparse matrices}

To reduce memory usage for large single-cell count matrices, we use a ``layered matrix" approach that splits the input matrix by row into 3 sparse submatrices.
The first, second and third submatrices contain data for genes where all non-zero counts can fit into 8-bit, 16-bit and 32-bit unsigned integers, respectively.
This improves memory efficiency as large datasets generally have low coverage and can be mostly represented as 8-bit integers.
The same strategy is applied to row indices for non-zero elements in a sparse matrix; most datasets with fewer than 60,000 genes can be accommodated with 16-bit integers.
This gives a theoretical usage of 3 bytes per non-zero element, e.g., a dataset with 30,000 genes and 100,000 cells at 5\% density requires around 500 MB of memory.

The layered matrix representation is implemented through the delayed binding mechanism in \code{tatami}.
Specifically, we create the individual sparse submatrices and then create an abstract represention of the full matrix where the submatrices are combined by row.
This preserves the memory-efficient representation while presenting an interface that mimics that of a single matrix.
The layered representation can then be seamlessly used with all existing code compatible with the \code{tatami} interface.
Note that the genes are permuted from their supplied order, which requires some extra attention in downstream analyses.

% Need to add memory usage here.

\section{User interface concepts}

\subsection{Interlinked graphics}

Different panels of the \code{kana} application (Figure \ref{screenshot:results}) can share information with each other to facilitate interactive exploration of the dataset.
For example, we can color the embedding according to the expression of a gene selected from the marker table.
Upon selection, \code{kana} retrieves the log-normalized expression values for that gene from the sparse matrix and passes this data to the scatter plot for coloring.
Users can also adjust the color gradient to improve contrast and highlight differences at particular ranges of expression.

A more complex example involves the detection of new marker genes for a custom selection of cells.
Users can create a custom selection by brushing on regions of interest in the embedding panel.
If this selection is saved, \code{kana} will perform a differential expression analysis to detect upregulation inside the selection compared to all other cells.
Statistics for each gene are then shown in the marker table for examination.
Each custom selection and its statistics are treated as part of the analysis state and are saved during export.

Users can also save specific views of the embeddings into the gallery for later perusal (CIRROCUMULUS).
This is useful for simultaneously viewing multiple plots colored by different marker genes to characterize complex populations.

\subsection{Progressive rendering}

Each result is immediately rendered on the interface once the corresponding analysis step is complete.
For example, the distribution of QC metrics appear once the QC step is finished, followed by the plot of the percentage of variance explained once the PCA is done, and so on.
This improves application performance by avoiding the rendering bottleneck that would otherwise occur all plots were drawn at once. 
It also serves as a visual progress indicator and improves the user experience by showing meaningful content as soon as possible.

The marker table is a more subtle example of progressive rendering.
Only the genes in the current view of the table are rendered, with the remaining visual elements being dynamically created as the user scrolls up or down to see other genes in the ranking.
This ensures that we do not waste time rendering tens of thousands of rows when only the top few are likely to be viewed.

As \code{kana} is doing the analysis in the background, we can actively monitor the change in the embeddings across t-SNE iterations or UMAP epochs.
We do so by extracting the coordinates at various intervals and rendering them on the embedding panel,
effectively creating an animation of the embedding as it is refined over time.
This is mostly provided for entertainment value but may also provide some educational insights into how these embeddings work.

\subsection{Exporting and reloading}

Users can choose to export their analyses to the browser's cache via its in-built \code{IndexedDB} database system.
This dumps the analysis state (i.e., parameters and results) into a Gzip-compressed JSON inside the cache, along with the input data files.
Users can then reload their analysis in a new browser session without needing to keep track of any files.
Moreover, \code{kana} will attempt to deduplicate input files in the cache based on the file name, size and MD5 checksum.
This reduces disk usage when storing multiple analysis states for the same dataset. 

Alternatively, users may export the analysis state to a file that is downloaded to the their machine.
This creates a single binary file containing the Gzip-compressed analysis state and the embedded input files.
Supplying this file to \code{kana} will then restore the previous analysis in the same manner as using the browser cache.
The benefit of this approach is that files exported by one user can be reloaded by other users on different machines,
allowing users to easily share their analyses with each other by simply transferring the relevant files.

\bibliography{ref.bib}
\bibliographystyle{plain}

\end{document}
